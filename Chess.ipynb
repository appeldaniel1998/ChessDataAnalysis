{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-15T12:21:09.530350Z",
     "start_time": "2024-07-15T12:21:09.456913Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ],
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T10:42:37.144056Z",
     "start_time": "2024-07-15T10:41:13.254217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Preprocecing\n",
    "#First of all we will check how many null values there are in each column\n",
    "df = pd.read_csv('chess_games.csv')\n",
    "\n",
    "df_first_lines = df.head(500000)\n",
    "df_first_lines.to_csv('shorterChessDf.csv', index=False)\n"
   ],
   "id": "e41642d5a712d26c",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T10:42:49.582407Z",
     "start_time": "2024-07-15T10:42:49.577901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the function to split chess moves\n",
    "def split_chess_moves(moves, turns):\n",
    "    move_list = moves.split()\n",
    "    separated_moves = []\n",
    "    turn_number = 1\n",
    "    for i in range(0, len(move_list), 3):\n",
    "        if turn_number > turns:\n",
    "            break\n",
    "        separated_moves.append(move_list[i + 1] if i + 1 < len(move_list) else \"\")\n",
    "        separated_moves.append(move_list[i + 2] if i + 2 < len(move_list) else \"\")\n",
    "        turn_number += 1\n",
    "    return separated_moves"
   ],
   "id": "8b5a72c36cc93f61",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T10:42:49.590919Z",
     "start_time": "2024-07-15T10:42:49.583414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_result(result):\n",
    "    if result == '1-0':\n",
    "        return 1\n",
    "    elif result == '0-1':\n",
    "        return 0\n",
    "    elif result == '1/2-1/2':\n",
    "        return 2\n",
    "    else:\n",
    "        return -1  # for any unexpected result format"
   ],
   "id": "1ee4a2ad57287de2",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T10:44:02.825182Z",
     "start_time": "2024-07-15T10:42:49.591924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('shorterChessDf.csv')  # Load the DataFrame\n",
    "\n",
    "df['Result'] = df['Result'].apply(lambda x: determine_result(x))  # Apply the determine_result function\n",
    "\n",
    "number_of_turns = 20  # Specify the number of turns we want to extract\n",
    "\n",
    "# Create new columns for the specified number of turns\n",
    "columns = [f\"Turn {i + 1} White\" for i in range(number_of_turns)] + [f\"Turn {i + 1} Black\" for i in range(number_of_turns)]\n",
    "\n",
    "# Apply the split_chess_moves function to each row in the DataFrame\n",
    "moves_split = df['AN'].apply(lambda x: pd.Series(split_chess_moves(x, number_of_turns)))\n",
    "\n",
    "df[columns] = moves_split  # Combine the new columns with the original DataFrame\n",
    "\n",
    "# Drop specified columns\n",
    "df.drop(columns=['Event', 'White', 'Black', 'UTCDate', 'UTCTime', 'WhiteElo', 'BlackElo', 'WhiteRatingDiff',\n",
    "                 'BlackRatingDiff', 'ECO', 'Opening', 'TimeControl', 'Termination', 'AN'], inplace=True)\n",
    "\n",
    "# Save the modified DataFrame to a CSV file\n",
    "output_file = 'modified_dataframe.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "df.head()"
   ],
   "id": "8973514d8cf229a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Result Turn 1 White Turn 2 White Turn 3 White Turn 4 White Turn 5 White  \\\n",
       "0       1           d4           d5           c4           c6           e3   \n",
       "1       0           e4           e5           b3          Nf6          Bb2   \n",
       "2       1           e4           d5         exd5         Qxd5          Nf3   \n",
       "3       1           e3          Nf6          Bc4           d6           e4   \n",
       "4       0           e4           c5          Nf3           d6           d4   \n",
       "\n",
       "  Turn 6 White Turn 7 White Turn 8 White Turn 9 White  ... Turn 11 Black  \\\n",
       "0           a6          Nf3           e5         cxd5  ...          Rac1   \n",
       "1          Nc6          Nf3           d6           d3  ...          Rxc7   \n",
       "2          Bg4          Be2          Nf6          Nc3  ...          Qxb7   \n",
       "3           e6          Nf3         Nxe4          Nd4  ...          Nxh3   \n",
       "4         cxd4         Nxd4          Nf6          Nc3  ...           Ne2   \n",
       "\n",
       "  Turn 12 Black Turn 13 Black Turn 14 Black Turn 15 Black Turn 16 Black  \\\n",
       "0           Qd6           Qc2           Qe6           Nb1           Bd6   \n",
       "1          Nxa2           Ra1           Nb4         Raxa7          Rxa7   \n",
       "2           Bg4          Qc6+           Ke7          Rae1          Rxh4   \n",
       "3           g5+          Nxg5         fxg5+          Kxg5          Rh5+   \n",
       "4           Qd8           Bb6           Qe8           Be3           Ra6   \n",
       "\n",
       "  Turn 17 Black Turn 18 Black Turn 19 Black Turn 20 Black  \n",
       "0            a3           Nb6           Qc6          Nfd5  \n",
       "1          Rxa7          Nxe4          Nxe4          Rxe4  \n",
       "2          Nd5+           Kf8          Nxf6          Qxf6  \n",
       "3         Qxh5+           Kd7          Qf7+           Kd6  \n",
       "4            c4           Nh5           Ng3          Nxg3  \n",
       "\n",
       "[5 rows x 41 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>Turn 1 White</th>\n",
       "      <th>Turn 2 White</th>\n",
       "      <th>Turn 3 White</th>\n",
       "      <th>Turn 4 White</th>\n",
       "      <th>Turn 5 White</th>\n",
       "      <th>Turn 6 White</th>\n",
       "      <th>Turn 7 White</th>\n",
       "      <th>Turn 8 White</th>\n",
       "      <th>Turn 9 White</th>\n",
       "      <th>...</th>\n",
       "      <th>Turn 11 Black</th>\n",
       "      <th>Turn 12 Black</th>\n",
       "      <th>Turn 13 Black</th>\n",
       "      <th>Turn 14 Black</th>\n",
       "      <th>Turn 15 Black</th>\n",
       "      <th>Turn 16 Black</th>\n",
       "      <th>Turn 17 Black</th>\n",
       "      <th>Turn 18 Black</th>\n",
       "      <th>Turn 19 Black</th>\n",
       "      <th>Turn 20 Black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>d4</td>\n",
       "      <td>d5</td>\n",
       "      <td>c4</td>\n",
       "      <td>c6</td>\n",
       "      <td>e3</td>\n",
       "      <td>a6</td>\n",
       "      <td>Nf3</td>\n",
       "      <td>e5</td>\n",
       "      <td>cxd5</td>\n",
       "      <td>...</td>\n",
       "      <td>Rac1</td>\n",
       "      <td>Qd6</td>\n",
       "      <td>Qc2</td>\n",
       "      <td>Qe6</td>\n",
       "      <td>Nb1</td>\n",
       "      <td>Bd6</td>\n",
       "      <td>a3</td>\n",
       "      <td>Nb6</td>\n",
       "      <td>Qc6</td>\n",
       "      <td>Nfd5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>e4</td>\n",
       "      <td>e5</td>\n",
       "      <td>b3</td>\n",
       "      <td>Nf6</td>\n",
       "      <td>Bb2</td>\n",
       "      <td>Nc6</td>\n",
       "      <td>Nf3</td>\n",
       "      <td>d6</td>\n",
       "      <td>d3</td>\n",
       "      <td>...</td>\n",
       "      <td>Rxc7</td>\n",
       "      <td>Nxa2</td>\n",
       "      <td>Ra1</td>\n",
       "      <td>Nb4</td>\n",
       "      <td>Raxa7</td>\n",
       "      <td>Rxa7</td>\n",
       "      <td>Rxa7</td>\n",
       "      <td>Nxe4</td>\n",
       "      <td>Nxe4</td>\n",
       "      <td>Rxe4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>e4</td>\n",
       "      <td>d5</td>\n",
       "      <td>exd5</td>\n",
       "      <td>Qxd5</td>\n",
       "      <td>Nf3</td>\n",
       "      <td>Bg4</td>\n",
       "      <td>Be2</td>\n",
       "      <td>Nf6</td>\n",
       "      <td>Nc3</td>\n",
       "      <td>...</td>\n",
       "      <td>Qxb7</td>\n",
       "      <td>Bg4</td>\n",
       "      <td>Qc6+</td>\n",
       "      <td>Ke7</td>\n",
       "      <td>Rae1</td>\n",
       "      <td>Rxh4</td>\n",
       "      <td>Nd5+</td>\n",
       "      <td>Kf8</td>\n",
       "      <td>Nxf6</td>\n",
       "      <td>Qxf6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>e3</td>\n",
       "      <td>Nf6</td>\n",
       "      <td>Bc4</td>\n",
       "      <td>d6</td>\n",
       "      <td>e4</td>\n",
       "      <td>e6</td>\n",
       "      <td>Nf3</td>\n",
       "      <td>Nxe4</td>\n",
       "      <td>Nd4</td>\n",
       "      <td>...</td>\n",
       "      <td>Nxh3</td>\n",
       "      <td>g5+</td>\n",
       "      <td>Nxg5</td>\n",
       "      <td>fxg5+</td>\n",
       "      <td>Kxg5</td>\n",
       "      <td>Rh5+</td>\n",
       "      <td>Qxh5+</td>\n",
       "      <td>Kd7</td>\n",
       "      <td>Qf7+</td>\n",
       "      <td>Kd6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>e4</td>\n",
       "      <td>c5</td>\n",
       "      <td>Nf3</td>\n",
       "      <td>d6</td>\n",
       "      <td>d4</td>\n",
       "      <td>cxd4</td>\n",
       "      <td>Nxd4</td>\n",
       "      <td>Nf6</td>\n",
       "      <td>Nc3</td>\n",
       "      <td>...</td>\n",
       "      <td>Ne2</td>\n",
       "      <td>Qd8</td>\n",
       "      <td>Bb6</td>\n",
       "      <td>Qe8</td>\n",
       "      <td>Be3</td>\n",
       "      <td>Ra6</td>\n",
       "      <td>c4</td>\n",
       "      <td>Nh5</td>\n",
       "      <td>Ng3</td>\n",
       "      <td>Nxg3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "after splitting the games to  moves, we want to remove all null values because there are 2 options:\n",
    "1. the game is shorter that the number of turns, and we do not want to consider it (null moves for not existing moves)\n",
    "2. there are missing moves during the game. i.e. not complete data - we want to remove it."
   ],
   "id": "cc80fd2ba4f5cd03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:17:11.447700Z",
     "start_time": "2024-07-15T11:17:04.432394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfFiltered = df.copy()\n",
    "dfFiltered = dfFiltered.dropna()\n",
    "dfFilteredAndCompacted = dfFiltered.head(50000)"
   ],
   "id": "28886b085730c967",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:17:33.528721Z",
     "start_time": "2024-07-15T11:17:33.224624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows_with_nulls = dfFilteredAndCompacted[dfFilteredAndCompacted.isnull().any(axis=1)]\n",
    "rows_with_nulls"
   ],
   "id": "8953082f8e1708b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Result, Turn 1 White, Turn 2 White, Turn 3 White, Turn 4 White, Turn 5 White, Turn 6 White, Turn 7 White, Turn 8 White, Turn 9 White, Turn 10 White, Turn 11 White, Turn 12 White, Turn 13 White, Turn 14 White, Turn 15 White, Turn 16 White, Turn 17 White, Turn 18 White, Turn 19 White, Turn 20 White, Turn 1 Black, Turn 2 Black, Turn 3 Black, Turn 4 Black, Turn 5 Black, Turn 6 Black, Turn 7 Black, Turn 8 Black, Turn 9 Black, Turn 10 Black, Turn 11 Black, Turn 12 Black, Turn 13 Black, Turn 14 Black, Turn 15 Black, Turn 16 Black, Turn 17 Black, Turn 18 Black, Turn 19 Black, Turn 20 Black]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>Turn 1 White</th>\n",
       "      <th>Turn 2 White</th>\n",
       "      <th>Turn 3 White</th>\n",
       "      <th>Turn 4 White</th>\n",
       "      <th>Turn 5 White</th>\n",
       "      <th>Turn 6 White</th>\n",
       "      <th>Turn 7 White</th>\n",
       "      <th>Turn 8 White</th>\n",
       "      <th>Turn 9 White</th>\n",
       "      <th>...</th>\n",
       "      <th>Turn 11 Black</th>\n",
       "      <th>Turn 12 Black</th>\n",
       "      <th>Turn 13 Black</th>\n",
       "      <th>Turn 14 Black</th>\n",
       "      <th>Turn 15 Black</th>\n",
       "      <th>Turn 16 Black</th>\n",
       "      <th>Turn 17 Black</th>\n",
       "      <th>Turn 18 Black</th>\n",
       "      <th>Turn 19 Black</th>\n",
       "      <th>Turn 20 Black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here, we have verified that the data contains no NaNs or Nulls",
   "id": "d70a5b5abd0c01a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:28:35.935437Z",
     "start_time": "2024-07-15T11:28:35.170849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group by these columns and identify groups with more than one entry\n",
    "duplicate_groups = dfFilteredAndCompacted.groupby(list(dfFilteredAndCompacted.columns[1:])).size()\n",
    "duplicate_groups = duplicate_groups[duplicate_groups > 1]\n",
    "\n",
    "# Show the duplicate groups\n",
    "duplicate_groups"
   ],
   "id": "6a7fc5f40961f4c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Turn 1 White  Turn 2 White  Turn 3 White  Turn 4 White  Turn 5 White  Turn 6 White  Turn 7 White  Turn 8 White  Turn 9 White  Turn 10 White  Turn 11 White  Turn 12 White  Turn 13 White  Turn 14 White  Turn 15 White  Turn 16 White  Turn 17 White  Turn 18 White  Turn 19 White  Turn 20 White  Turn 1 Black  Turn 2 Black  Turn 3 Black  Turn 4 Black  Turn 5 Black  Turn 6 Black  Turn 7 Black  Turn 8 Black  Turn 9 Black  Turn 10 Black  Turn 11 Black  Turn 12 Black  Turn 13 Black  Turn 14 Black  Turn 15 Black  Turn 16 Black  Turn 17 Black  Turn 18 Black  Turn 19 Black  Turn 20 Black\n",
       "e4            c5            Nf3           e6            d4            cxd4          Nxd4          Nf6           Nc3           Bb4            Bg5            Qa5            Bd2            Qe5            Ndb5           Nxe4           Nxe4           Qxe4+          Be2            Na6            Bxb4          Qxb4+         c3            Qxb2          Rb1           Qxa2          Nd6+          Ke7           O-O           Qd5            Nxc8+          Rhxc8          Qxd5           exd5           Rxb7           Nc5            Rb5            Ne4            Rxd5           Nxc3             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We are looking for duplicated data. we found 1 duplicate which appears twice in the data. <br>\n",
    "there are 2 scenarios where this may happen: <br>\n",
    "   1. the whole game is duplicated by chance or by an error in the data (human or otherwise)\n",
    "   2. The first 20 moves in the two games are coincidentally the same. <br>\n"
   ],
   "id": "1e8866bee800df02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Whichever of the cases is correct, this is only 1 duplicate from the 50,000 records in the data, so it has little to no impact on the results for our purposes.<br><br>\n",
    "Since our features are not numeric, and we do not want to limit the data by confiding it to be numeric, linear correlation and various other analysis techniques cannot be performed."
   ],
   "id": "5667302f349e4b89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "84337b2b4b4e989e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:02:07.357359Z",
     "start_time": "2024-07-15T12:02:07.291761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = dfFilteredAndCompacted['Result']\n",
    "x = dfFilteredAndCompacted.drop(['Result'], axis=1)"
   ],
   "id": "2681eeb9488fe8cd",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:03:41.411305Z",
     "start_time": "2024-07-15T12:03:40.057373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract all unique moves from the DataFrame\n",
    "moves = set(x.values.flatten())\n",
    "moves = {move for move in moves if pd.notnull(move)}\n",
    "\n",
    "# Create a mapping of moves to numeric values\n",
    "move_to_num = {move: i for i, move in enumerate(moves)}\n",
    "\n",
    "# Function to convert moves to numeric values using the mapping\n",
    "def convert_moves_to_numeric(move):\n",
    "    return move_to_num.get(move, -1)  # Use -1 for any missing or unknown moves\n",
    "\n",
    "# Apply the conversion to the DataFrame\n",
    "x = x.map(convert_moves_to_numeric)"
   ],
   "id": "dfbbb746baba37b5",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:03:45.230759Z",
     "start_time": "2024-07-15T12:03:45.229117Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c278bff1a50e1be4",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:03:02.930318Z",
     "start_time": "2024-07-15T12:03:02.927304Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d65365a039612c68",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:49:30.116134Z",
     "start_time": "2024-07-15T11:49:30.054985Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4e887630aa789ce7",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:03:48.129072Z",
     "start_time": "2024-07-15T12:03:48.101240Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)",
   "id": "36fef64dc958c3ae",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:03:51.653859Z",
     "start_time": "2024-07-15T12:03:51.646231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dummyModel = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummyModel.fit(X_train, y_train)\n",
    "predictionsDummy = dummyModel.predict(X_test)\n",
    "\n",
    "accuracyDummy = metrics.accuracy_score(y_test, predictionsDummy)\n",
    "accuracyDummy"
   ],
   "id": "2c3c4f61878cc888",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4846"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:03:51.657089Z",
     "start_time": "2024-07-15T12:03:51.654367Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "84d830e3560ab727",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:12:55.764369Z",
     "start_time": "2024-07-15T12:12:55.135927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Create a pipeline that scales the data and then applies logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=1000, solver='lbfgs'))  # Handle multi-class\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)  # Fit the pipeline on the training data\n",
    "predictionsLogReg = pipeline.predict(X_test)  # Make predictions\n",
    "accuracyLogReg = accuracy_score(y_test, predictionsLogReg)  # Calculate accuracy\n",
    "print(\"Logistic Regression Accuracy:\", accuracyLogReg)  # Print the accuracy"
   ],
   "id": "aa131334f9e7a457",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.4886\n"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:14:02.430570Z",
     "start_time": "2024-07-15T12:14:02.427654Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "25f7f3e8be98651c",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:18:14.924226Z",
     "start_time": "2024-07-15T12:15:27.776802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#AdaBoost\n",
    "start_timeAdaBoost = time.time()\n",
    "modelDecTree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "modelAdaBoost = AdaBoostClassifier(modelDecTree, n_estimators = 1000, random_state = 0, learning_rate = 1)\n",
    "modelAdaBoost.fit(X_train, y_train)\n",
    "predictionsAdaBoost = modelAdaBoost.predict(X_test)\n",
    "accuracyAdaBoost = metrics.accuracy_score(y_test, predictionsAdaBoost)\n",
    "print(\"Accuracy (AdaBoost): \", accuracyAdaBoost)\n",
    "timeAdaBoost = time.time() - start_timeAdaBoost\n",
    "print(\"Time taken to achieve result: %s seconds\" % timeAdaBoost)"
   ],
   "id": "27635e393ed4f299",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\appel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (AdaBoost):  0.5034\n",
      "Time taken to achieve result: 167.02821230888367 seconds\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:25:36.260500Z",
     "start_time": "2024-07-15T12:24:58.172289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Random Forests\n",
    "start_timeRandForests = time.time()\n",
    "modelRandForests = RandomForestClassifier(n_estimators = 1000, n_jobs = -1, random_state = 0)\n",
    "modelRandForests.fit(X_train, y_train)\n",
    "predictionsRandForests = modelRandForests.predict(X_test)\n",
    "accuracyRandForests = metrics.accuracy_score(y_test, predictionsRandForests)\n",
    "print(\"Accuracy (Random Forests): \", accuracyRandForests)\n",
    "timeRandForests = time.time() - start_timeRandForests\n",
    "print(\"Time taken to achieve result: %s seconds\" % (timeRandForests))"
   ],
   "id": "47a15bfd3f684819",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Random Forests):  0.5193\n",
      "Time taken to achieve result: 38.084845542907715 seconds\n"
     ]
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:30:06.018269Z",
     "start_time": "2024-07-15T12:29:27.276384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "#XGBoost\n",
    "start_timeXGBoost = time.time()\n",
    "warnings.filterwarnings('ignore')\n",
    "modelXGBoost = XGBClassifier(learning_rate = 0.2, n_estimators = 2000, verbosity = 0, use_label_encoder = False, n_jobs = -1)\n",
    "modelXGBoost.fit(X_train, y_train)\n",
    "predictionsXGBoost = modelXGBoost.predict(X_test)\n",
    "accuracyXGBoost = metrics.accuracy_score(y_test, predictionsXGBoost)\n",
    "print(\"Accuracy (XGBoost): \", accuracyXGBoost)\n",
    "timeXGBoost = time.time() - start_timeXGBoost\n",
    "print(\"Time taken to achieve result: %s seconds\" % (timeXGBoost))"
   ],
   "id": "9ecc1c040ad42690",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (XGBoost):  0.5124\n",
      "Time taken to achieve result: 38.73734736442566 seconds\n"
     ]
    }
   ],
   "execution_count": 157
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e96252db4ace087a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the model with regularization and dropout\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=512, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate model performance on validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_val_scaled, y_val)\n",
    "print(\"Validation Loss:\", val_loss)\n",
    "print(\"Validation Accuracy:\", val_accuracy)"
   ],
   "id": "ec7976483278558f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
